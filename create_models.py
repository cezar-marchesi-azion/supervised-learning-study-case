import re
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegressionCV
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.pipeline import Pipeline
import matplotlib.pyplot as plt
import seaborn as sns
import pickle


from reddit_api import api_reddit


## Loading data

# Subjects that will be used for the exercise
subjects = ['datascience', 'machinelearning',
            'physics', 'astrology', 'conspiracy']


def load_data():

    # Only fetch posts with >100 characters
    char_count = lambda post: len(re.sub('\W|\d', '', post.selftext))
    mask = lambda post: char_count(post) >= 100

    data = []
    labels = []

    for i, subject in enumerate(subjects):

        subreddit_data = api_reddit.subreddit(subject).new(limit=1000)
        posts = [post.selftext for post in filter(mask, subreddit_data)]

        data.extend(posts)
        labels.extend([i] * len(posts))

        print(f'Number of posts for r/{subject}: {len(posts)}',
              f'\nAn example: {posts[0][:600]}...\n',
              '-' * 80 + '\n')
              
    return data, labels


## Split data into Train and Test datasets

# 20% of data will be for tests
TEST_SIZE = .2
# Generate always the same randomness pattern for the purpose of the exercise
RANDOM_STATE = 0

def split_data():
    
    x_training, x_testing, y_training, y_testing = train_test_split(data,
                                                                    labels,
                                                                    test_size=TEST_SIZE,
                                                                    random_state=RANDOM_STATE)

    print(f'{len(y_testing)} testing sample')                                                                    

    return x_training, x_testing, y_training, y_testing


## Data pre-processing and Attribute extraction

MIN_DOC_FREQ = 1
N_COMPONENTS = 1000
N_ITER = 30

def preprocessing_pipeline():

    # Remove symbols, numbers and url-like strings
    pattern = r'\W|\d|http.*\s+|www.*\s+'
    preprocessor = lambda text: re.sub(pattern, ' ', text)

    # Vectorize text with TF-IDF
    # TfidfVectorizer will transform the text into a meaningful representation of integers
    # to fit the machine learning algorithm
    vectorizer = TfidfVectorizer(preprocessor=preprocessor, stop_words='english', min_df=MIN_DOC_FREQ)

    # TruncatedSVD to reduce dimensions of the sparse matrix generated by TfidfVectorizer
    decomposition = TruncatedSVD(n_components=N_COMPONENTS, n_iter=N_ITER)

    pipeline = [('tfidf', vectorizer), ('svd', decomposition)]

    return pipeline


N_NEIGHBORS = 4
CV = 3

def create_models():

    # Trying out different classification models
    model_1 = KNeighborsClassifier(n_neighbors=N_NEIGHBORS)
    model_2 = RandomForestClassifier(random_state=RANDOM_STATE)
    model_3 = LogisticRegressionCV(cv=CV, random_state=RANDOM_STATE)

    models = [('KNN', model_1), ('RandomForest', model_2), ('LogReg', model_3)]

    return models

def train_and_assess(models, pipeline, x_train, x_test, y_train, y_test):
    
    results = []

    for name, model in models:
        pipe = Pipeline(pipeline + [(name, model)])

        # Training
        print(f'Training model: {name}')
        pipe.fit(x_train, y_train)

        filename = name + '_model.sav'
        pickle.dump(model, open(filename, 'wb'))

        # Predictions with test data
        y_pred = pipe.predict(x_test)

        # Calculate metrics
        report = classification_report(y_test, y_pred)
        print("Classification report:\n", report)

        results.append([model, {'model': name, 'predictions': y_pred, 'report': report,}])

    return results


if __name__ == "__main__":

    data, labels = load_data()

    x_training, x_testing, y_training, y_testing = split_data()

    pipeline = preprocessing_pipeline()

    all_models = create_models()

    results = train_and_assess(all_models, pipeline, x_training, x_testing, y_training, y_testing)    

    print("Finished")

# Visualizing the results

def plot_distribution():
    _, counts = np.unique(labels, return_counts=True)
    sns.set_theme(style='whitegrid')
    plt.figure(figsize=(15, 6), dpi=120)
    plt.title("Number os posts by subject")
    sns.barplot(x= subjects, y=counts)
    plt.legend([' '.join([f.title(), f'- {c} posts']) for f,c in zip(subjects, counts)])
    plt.show()

def plot_confusion(result):    
    print('Classification report\n', result[-1]['report'])
    y_pred = result[-1]['predictions']
    conf_matrix = confusion_matrix(y_testing, y_pred)
    _, test_counts = np.unique(y_testing, return_counts=True)
    conf_matrix_percent = conf_matrix / test_counts.transpose() * 100
    plt.figure(figsize=(9,8), dpi=120)
    plt.title(result[-1]['model'].upper() + ' Results')
    plt.xlabel('Real value')
    plt.ylabel('Model prediction')
    ticklabels = [f'r/{sub}' for sub in subjects]
    sns.heatmap(data=conf_matrix_percent, xticklabels=ticklabels, yticklabels=ticklabels, annot=True, fmt ='.2f')
    plt.show()


plot_distribution()
plot_confusion(results[0])
plot_confusion(results[1])
plot_confusion(results[2])
